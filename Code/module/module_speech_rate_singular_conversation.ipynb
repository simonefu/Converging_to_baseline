{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cmath as mt\n",
    "from matplotlib import colors\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import sklearn.cross_validation\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn\n",
    "from sklearn.linear_model import LinearRegression\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = pd.read_pickle('..\\output\\data.pkl')\n",
    "def download_data(n_directory,name_file):\n",
    "    path = '..\\output\\X' + str(n_directory) + '\\\\'\n",
    "    path_name_file = str(path) + str(name_file) + '.pkl'\n",
    "    file = pd.read_pickle(path_name_file)\n",
    "    return file \n",
    "\n",
    "def upload_data(N,file,name_file):\n",
    "    path = '..\\output\\X' + str(N) + '\\\\'\n",
    "    path_name_file_plk = str(path) + str(name_file) + '.pkl'\n",
    "    path_name_file_csv = str(path) + str(name_file) + '.csv'    \n",
    "    file.to_pickle(path_name_file_plk)\n",
    "    file.to_csv(path_name_file_csv, sep='\\t', encoding='utf-8')\n",
    "    return path_name_file_plk \n",
    "\n",
    "def linear_regression_parameter(X, test_SIZE):\n",
    "# Use only one feature\n",
    "    X_input = X[['lenght_utterance','distance_to_end','median_duration']]\n",
    "    Y_output = X['duration']\n",
    "\n",
    "# Split the data into training/testing sets\n",
    "# Split the targets into training/testing sets\n",
    "\n",
    "    if test_SIZE == 0:\n",
    "        X_train = X_input\n",
    "        Y_train = Y_output\n",
    "    else:    \n",
    "        X_train, X_test, Y_train, Y_test = sklearn.cross_validation.train_test_split(X_input, Y_output, test_size = test_SIZE, random_state = 5)\n",
    "\n",
    "\n",
    "# Create linear regression object\n",
    "    regr = linear_model.LinearRegression()\n",
    "\n",
    "# Train the model using the training sets\n",
    "    regr.fit(X_train, Y_train)\n",
    "    parameters = pd.DataFrame(list(zip(X_input.columns,regr.coef_)), columns= ['features','estimate_coefficients'])\n",
    "    print(parameters)\n",
    "\n",
    "    if test_SIZE == 0:\n",
    "        return regr,parameters, X_train, Y_train\n",
    "    else:\n",
    "        \n",
    "    \n",
    "    \n",
    "    # Make predictions using the testing set\n",
    "        Y_pred = regr.predict(X_test) \n",
    "\n",
    "# The coefficients\n",
    "# The mean squared error\n",
    "        print(\"\\nMean squared error: %.3f\" % mean_squared_error(Y_test, Y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "        print('\\nVariance score: %.2f' % r2_score(Y_test, Y_pred))\n",
    "\n",
    "# Plot outputs\n",
    "        Y_test=pd.DataFrame(Y_test)\n",
    "        result = pd.concat([ Y_test, X_test], axis=1)\n",
    "        index_selected = result.index.values\n",
    "        df = pd.DataFrame({'index': index_selected, 'predicted_duration': Y_pred})\n",
    "        df = df.set_index('index')\n",
    "        result = pd.concat([ df, result], axis=1)\n",
    "        result['distance_to_end'] = pd.to_numeric(result['distance_to_end'], errors='coerce').fillna(0)\n",
    "        result['lenght_utterance'] = pd.to_numeric(result['lenght_utterance'], errors='coerce').fillna(0)\n",
    "    \n",
    "        result.plot(x = 'distance_to_end', y = 'predicted_duration', kind = 'scatter', grid=False,  alpha = 0.15,color='black', figsize= (15,10))\n",
    "        result.plot(x = 'distance_to_end', y = 'duration', kind = 'scatter', grid=False,  alpha = 0.15,color='blue', figsize= (15,10))\n",
    "        plt.xlabel(\"Distance utterance to the end (word)\")\n",
    "        plt.ylabel(\"Duration(s) \")\n",
    "        plt.title(\"Expected & real duration vs distance utterance to the end \")\n",
    "        plt.show()\n",
    "    \n",
    "        return regr,parameters, result, X_train, Y_train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speech_rate_computation_2(X_processed, id_conv, id_speaker, word_to_exclude, word_trash):\n",
    "    \n",
    "    X_filtered_expected = X_processed[(~X_processed['word'].isin(word_to_exclude))]\n",
    "    X_filtered_expected = X_filtered_expected[(X_filtered_expected['ID_conversation'] == id_conv) & (X_filtered_expected['ID_speaker'] == id_speaker)]\n",
    "    \n",
    "    X_filtered_real = X_processed[(~X_processed['word'].isin(word_trash))]\n",
    "    X_filtered_real = X_filtered_real[(X_filtered_real['ID_conversation'] == id_conv) & (X_filtered_real['ID_speaker'] == id_speaker)]\n",
    "    \n",
    "    id_utterance = X_filtered_real['ID_utterance'].unique()\n",
    "    for indice_id in id_utterance:\n",
    "        X_filtered_utterance = X_filtered_real[X_filtered_real['ID_utterance'] == indice_id]\n",
    "    \n",
    "        codition_init = True\n",
    "        condition_dataframe_not_empty = True\n",
    "        while codition_init & condition_dataframe_not_empty:\n",
    "            if X_filtered_utterance['word'].iloc[0] in word_to_exclude:\n",
    "                indici = X_filtered_utterance.index\n",
    "                c = indici[0]\n",
    "                X_filtered_real.drop(c, inplace=True)\n",
    "                X_filtered_utterance.drop(c, inplace=True)\n",
    "                condition_dataframe_not_empty = ~X_filtered_utterance.empty\n",
    "            else:\n",
    "                codition_init = False\n",
    "            \n",
    "        codition_init = True\n",
    "        condition_dataframe_not_empty = ~X_filtered_utterance.empty\n",
    "        while codition_init & condition_dataframe_not_empty:\n",
    "            if X_filtered_utterance['word'].iloc[-1] in word_to_exclude:\n",
    "                indici = X_filtered_utterance.index\n",
    "                c = indici[-1]\n",
    "                X_filtered_real.drop(c, inplace=True)\n",
    "                X_filtered_utterance.drop(c, inplace=True)\n",
    "                condition_dataframe_not_empty = ~X_filtered_utterance.empty\n",
    "            else:\n",
    "                codition_init = False       \n",
    "       \n",
    "    real_duration = X_filtered_real.groupby(['ID_utterance'])['duration'].sum()\n",
    "   # print(real_duration)\n",
    "    expected_duration = X_filtered_expected.groupby(['ID_utterance'])['expected_duration'].sum()\n",
    "   # print(expected_duration)\n",
    "    pointwise_speech_rate = real_duration/expected_duration\n",
    "\n",
    "    mean_log_pointwise_speech_rate = (np.log(pointwise_speech_rate)).mean() \n",
    "    mean_pointwise_speech_rate = pointwise_speech_rate.mean()\n",
    "    \n",
    "    real_duration_time = X_filtered_real.groupby(['ID_utterance'])['end_time'].max() - X_filtered_real.groupby(['ID_utterance'])['start_time'].min()\n",
    "    t = real_duration_time.mean() + X_filtered_real.groupby(['ID_utterance'])['start_time'].min()\n",
    "    \n",
    "\n",
    "   # return [X_filtered_real, X_filtered_expected, pointwise_speech_rate]\n",
    "    return [id_conv, mean_log_pointwise_speech_rate, pointwise_speech_rate, t, X_filtered_real, X_filtered_expected]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_conv(id_conv,N_degree_fit, n_point_interpolation,n_window, word_to_exclude,word_trash, X_processed, speaker_speech_rate):\n",
    "\n",
    "    [id_conv_A, mean_log_pointwise_speech_rate_A, pointwise_speech_rate_A, t_A, X_filtered_real_A, X_filtered_expected_A] = speech_rate_computation_2(X_processed, str(id_conv), 'A', word_to_exclude, word_trash)\n",
    "    [id_conv_B, mean_log_pointwise_speech_rate_B, pointwise_speech_rate_B, t_B, X_filtered_real_B, X_filtered_expected_B] = speech_rate_computation_2(X_processed, str(id_conv), 'B', word_to_exclude, word_trash)\n",
    "    fig = plt.figure(figsize=(12,7))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    pointwise_speech_rate_A.index = range(len(pointwise_speech_rate_A))\n",
    "    pointwise_speech_rate_B.index = range(len(pointwise_speech_rate_B))\n",
    "\n",
    "\n",
    "    pointwise_speech_rate_B_v = pointwise_speech_rate_B.as_matrix()\n",
    "    t_B_v = t_B.as_matrix()\n",
    "    zB = np.polyfit(t_B_v, pointwise_speech_rate_B_v, N_degree_fit)\n",
    "    pB = np.poly1d(zB)\n",
    "    x_B = np.linspace(t_B_v[0], t_B_v[-1], n_point_interpolation)\n",
    "\n",
    "\n",
    "    pointwise_speech_rate_A_v = pointwise_speech_rate_A.as_matrix()\n",
    "    t_A_v = t_A.as_matrix()\n",
    "    zA = np.polyfit(t_A_v, pointwise_speech_rate_A_v, N_degree_fit)\n",
    "    pA = np.poly1d(zA)\n",
    "    x_A = np.linspace(t_A_v[0], t_A_v[-1], n_point_interpolation)\n",
    "    #y_new = f(x_new)\n",
    "    ax1.plot(x_A,pA(x_A), c='b',linestyle = '--', label='speaker A smooth')\n",
    "    ax1.plot(x_B,pB(x_B), c='r',linestyle = '--', label='speaker B smooth')\n",
    "\n",
    "    ax1.scatter(t_A, pointwise_speech_rate_A,linewidths=0.01,  c='b', label='speaker A')\n",
    "    ax1.scatter(t_B, pointwise_speech_rate_B,linewidths=0.01,  c='r', label='speaker B')\n",
    "    ax1.plot(t_A, pointwise_speech_rate_A,linewidth=0.5,  c='b')\n",
    "    ax1.plot(t_B, pointwise_speech_rate_B,linewidth=0.5, c='r')\n",
    "    plt.legend(loc='upper left');\n",
    "    plt.suptitle('Speech rate vs time, conversation %s' %id_conv, fontsize=20)\n",
    "    plt.xlabel('t(s)', fontsize=15)\n",
    "    plt.ylabel('speech rate', fontsize=12)\n",
    "    plt.show()\n",
    "\n",
    "    yA = pA(x_A)\n",
    "    xA = x_A\n",
    "    derA = - np.diff(yA) / np.diff(xA)\n",
    "\n",
    "    yB = pB(x_B)\n",
    "    xB = x_B\n",
    "    derB = - np.diff(yB) / np.diff(xB)\n",
    "\n",
    "\n",
    "#    fig1 = plt.figure(figsize=(12,7))\n",
    "#    ax2 = fig1.add_subplot(111)\n",
    "\n",
    "#    ax2.plot(xA[0:-1:], derA,  c='b', label='speaker A')\n",
    "#    ax2.plot(xB[0:-1:], derB, c='r', label='speaker B')\n",
    "\n",
    "#    plt.legend(loc='upper left');\n",
    "#    plt.suptitle('Derivative Speech rate vs time, conversation %s' %id_conv, fontsize=20)\n",
    "#    plt.xlabel('t(s)', fontsize=15)\n",
    "#    plt.ylabel('speech rate', fontsize=12)\n",
    "#    plt.show()\n",
    "\n",
    "    rollingB = pointwise_speech_rate_B.rolling(window=n_window)\n",
    "    rolling_meanB = rollingB.mean()\n",
    "    rollingA = pointwise_speech_rate_A.rolling(window=n_window)\n",
    "    rolling_meanA = rollingA.mean()\n",
    "\n",
    "\n",
    "    fig2 = plt.figure(figsize=(12,7))\n",
    "    ax3 = fig2.add_subplot(111)\n",
    "\n",
    "    ax3.plot(t_B_v,rolling_meanB,linestyle = '--',  c='r')\n",
    "\n",
    "    ax3.plot(t_A_v,rolling_meanA,linestyle = '--',  c='b')\n",
    "\n",
    "\n",
    "    ax3.scatter(t_A_v, rolling_meanA,linewidths=0.01,  c='b', label='Speaker')\n",
    "    ax3.scatter(t_B_v, rolling_meanB,linewidths=0.01,  c='r', label='Interlocutor')\n",
    "\n",
    "    rolling_meanB_noNan = rolling_meanB[~np.isnan(rolling_meanB)]\n",
    "    zB_average = np.polyfit(t_B_v[(n_window-1):], rolling_meanB_noNan, N_degree_fit)\n",
    "    pB_average = np.poly1d(zB_average)\n",
    "    x_B = np.linspace(t_B_v[(n_window-1)], t_B_v[-1], n_point_interpolation)\n",
    "\n",
    "    rolling_meanA_noNan = rolling_meanA[~np.isnan(rolling_meanA)]\n",
    "    zA_average = np.polyfit(t_A_v[(n_window-1):], rolling_meanA_noNan, N_degree_fit)\n",
    "    pA_average = np.poly1d(zA_average)\n",
    "    x_A = np.linspace(t_A_v[(n_window-1)], t_A_v[-1], n_point_interpolation)\n",
    "\n",
    "    ax3.plot(x_B,pB_average(x_B), c='r',linestyle = '-', label='Interlocutor smooth')\n",
    "    ax3.plot(x_A,pA_average(x_A), c='b',linestyle = '-', label='Speaker smooth')\n",
    "    \n",
    "    \n",
    "    baseline_A = speaker_speech_rate[(speaker_speech_rate['id_conv'] == id_conv) & (speaker_speech_rate['id_caller'] == 'A')].baseline_no_log_S.item()\n",
    "    baseline_B = speaker_speech_rate[(speaker_speech_rate['id_conv'] == id_conv) & (speaker_speech_rate['id_caller'] == 'A')].baseline_no_log_I.item()\n",
    "    \n",
    "    media_A = pointwise_speech_rate_A.mean() \n",
    "    x_A = [t_A.min(), t_A.max()]\n",
    "    y_A = [media_A, media_A]\n",
    "    ax3.plot(x_A,y_A, label='Speaker Mean')\n",
    "    y_baseline_A = [baseline_A,baseline_A]\n",
    "\n",
    "    ax3.plot(x_A,y_baseline_A, c = 'navy',label='Speaker Baseline')\n",
    "\n",
    "    media_B = pointwise_speech_rate_B.mean() \n",
    "    x_B = [t_B.min(), t_B.max()]\n",
    "    y_B = [media_B, media_B]\n",
    "    y_baseline_B = [baseline_B,baseline_B]\n",
    "    ax3.plot(x_B,y_B,c='hotpink', label='Interlocutor Mean')\n",
    "    ax3.plot(x_B,y_baseline_B,c='purple', label='Interlocutor Baseline')\n",
    "    ax3.set_position([0.08,0.08,0.75,0.8])\n",
    "        \n",
    "    \n",
    "    plt.suptitle('Speech Rate vs time, conversation %s' %id_conv, fontsize=20)\n",
    "    plt.xlabel('t(s)', fontsize=15)\n",
    "    plt.ylabel('speech rate', fontsize=12)\n",
    "    plt.legend()\n",
    "    ax3.legend(loc='center left', bbox_to_anchor=(1, 0.8))\n",
    "    \n",
    "    name_fig = './graphics/' + 'ID_' + str(id_conv) + '.png'\n",
    "    fig2.savefig(name_fig)\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "#_______________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def diff_speech_rate(N,X_processed,id_conv, word_to_exclude, word_trash):\n",
    "    [id_conv_A, mean_log_pointwise_speech_rate_A, pointwise_speech_rate_A, t_A, X_filtered_real_A, X_filtered_expected_A ] = speech_rate_computation_2(X_processed, str(id_conv), 'A', word_to_exclude, word_trash)\n",
    "    [id_conv_B, mean_log_pointwise_speech_rate_B, pointwise_speech_rate_B, t_B, X_filtered_real_B, X_filtered_expected_B] = speech_rate_computation_2(X_processed, str(id_conv), 'B', word_to_exclude, word_trash)\n",
    "    dA = {'speech_rate': pointwise_speech_rate_A, 'time': t_A}\n",
    "    df_A = pd.DataFrame(data=dA)\n",
    "    dB = {'speech_rate': pointwise_speech_rate_B, 'time': t_B}\n",
    "    df_B = pd.DataFrame(data=dB)\n",
    "    inf = min(t_A.min(), t_B.min())\n",
    "    sup = max(t_A.max(), t_B.max())\n",
    "    incr = (sup - inf)/N\n",
    "    limits = [(incr*i + inf)  for i in range(N + 1)]\n",
    "    sp_DA=[]\n",
    "    sp_DB=[]\n",
    "    time_DA = []\n",
    "    time_DB = []\n",
    "    time_vector_A = []\n",
    "    srate_vector_A = []\n",
    "    time_vector_B = []\n",
    "    srate_vector_B = []\n",
    "    \n",
    "\n",
    "    for j in range(N):\n",
    "\n",
    "        df_A_filterd = df_A[(df_A['time'] < limits[j+1]) & (df_A['time'] > limits[j])]\n",
    "        df_B_filterd = df_B[(df_B['time'] < limits[j+1]) & (df_B['time'] > limits[j])]\n",
    "        average_sp_dA = df_A_filterd['speech_rate'].mean()\n",
    "        average_sp_dB = df_B_filterd['speech_rate'].mean()\n",
    "        average_time_dA = df_A_filterd['time'].mean()\n",
    "        average_time_dB = df_B_filterd['time'].mean()\n",
    "\n",
    "#####################################################\n",
    "\n",
    "        time_vector_A.append(df_A_filterd['time'].values)\n",
    "        srate_vector_A.append(df_A_filterd['speech_rate'].values)\n",
    "        time_vector_B.append(df_B_filterd['time'].values)\n",
    "        srate_vector_B.append(df_B_filterd['speech_rate'].values)\n",
    "            \n",
    "    \n",
    "        sp_DA.append(average_sp_dA)\n",
    "        sp_DB.append(average_sp_dB)\n",
    "        time_DA.append(average_time_dA)\n",
    "        time_DB.append(average_time_dB)\n",
    "\n",
    "    diff_sp = [x - y for x, y in zip(sp_DA, sp_DB)]   \n",
    "    time_average = [x / 2 for x in limits]\n",
    "    duration = sup - inf\n",
    "    return [diff_sp,sp_DA, sp_DB, t_A.min(), t_A.max(), t_B.min(), t_B.max(), duration, time_vector_A, srate_vector_A, time_vector_B, srate_vector_B]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create file for the visualization data of Antoine Gaboin\n",
    "id_conv_list = X['ID_conversation'].unique()\n",
    "for id_conv in id_conv_list:\n",
    "    for id_speaker in ['A', 'B']:\n",
    "        [id_conv, mean_log_pointwise_speech_rate, pointwise_speech_rate, t, X_filtered_real,\n",
    "        X_filtered_expected] =speech_rate_computation_2(X, str(id_conv), id_speaker, word_to_exclude, word_trash)\n",
    "        pointwise_speech_rate = pd.DataFrame(pointwise_speech_rate)\n",
    "        t = pd.DataFrame(t)\n",
    "        speech_rate_conv = pd.concat([ pointwise_speech_rate, t], axis=1)\n",
    "        speech_rate_conv.columns = ['y', 't']\n",
    "        name_file = 'SW_' + str(id_conv) + '_speech_rate_' + id_speaker\n",
    "        upload_data(11,speech_rate_conv,name_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, sys\n",
    "\n",
    "# update_progress() : Displays or updates a console progress bar\n",
    "## Accepts a float between 0 and 1. Any int will be converted to a float.\n",
    "## A value under 0 represents a 'halt'.\n",
    "## A value at 1 or bigger represents 100%\n",
    "def update_progress(progress):\n",
    "    barLength = 20 # Modify this to change the length of the progress bar\n",
    "    status = \"\"\n",
    "    if isinstance(progress, int):\n",
    "        progress = float(progress)\n",
    "    if not isinstance(progress, float):\n",
    "        progress = 0\n",
    "        status = \"error: progress var must be float\\r\\n\"\n",
    "    if progress < 0:\n",
    "        progress = 0\n",
    "        status = \"Halt...\\r\\n\"\n",
    "    if progress >= 1:\n",
    "        progress = 1\n",
    "        status = \"Done...\\r\\n\"\n",
    "    block = int(round(barLength*progress))\n",
    "    text = \"\\rPercent: [{0}] {1}% {2}\".format( \"=\"*block + \" \"*(barLength-block), progress*100, status)\n",
    "    sys.stdout.write(text)\n",
    "    sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
